
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Introduction &#8212; plenoptic satellite event, VSS, 2025  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=7ee2dc7d" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'users/introduction-users';</script>
    <link rel="icon" href="../_static/plenoptic.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction" href="../presenters/introduction-presenters.html" />
    <link rel="prev" title="Introduction" href="../full/introduction.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/plenoptic.svg" class="logo__image only-light" alt="Home"/>
    <script>document.write(`<img src="../_static/plenoptic_darkmode.svg" class="logo__image only-dark" alt="Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/plenoptic-org/plenoptic-vss-2025" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://workshops.plenoptic.org/" title="Workshops home" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-house fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Workshops home</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://binder.flatironinstitute.org/v2/user/wbroderick/vss2025?filepath=introduction-stripped.ipynb" title="Binder" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://mybinder.org/badge_logo.svg" class="icon-link-image" alt="Binder"/></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to plenoptic satellite event, VSS 2025
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../can_you_read.html">Are You Sitting Too Far?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Full notebooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../full/introduction.html">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">For users (some code, some text)</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">For presenter reference (all code, no text)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../presenters/introduction-presenters.html">Introduction</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/plenoptic-org/plenoptic-vss-2025" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/users/introduction-users.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic-basics">Plenoptic basics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-model-invariances-with-metamers">Examining model invariances with metamers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-model-sensitivies-to-eigendistortions">Examining model sensitivies to eigendistortions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-complex-model">A more complex model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-some-nonlinear-features-to-the-mix">Adding some nonlinear features to the mix</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h1>
<p>This notebook has had all its explanatory text removed and has not been run.
It is intended to be downloaded and run locally (or on the provided binder)
while listening to the presenter’s explanation. In order to see the fully
rendered of this notebook, go <a class="reference internal" href="#../../full/introduction.md"><span class="xref myst">here</span></a></p>
<img src="../_static/models.png">
<p>For the purposes of this notebook, we’ll use some very simple convolutional models that are inspired by the processing done in the lateral geniculate nucleus (LGN) of the visual system<a class="footnote-reference brackets" href="#models" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. We’re going to build up in complexity, starting with the Gaussian model at the top and gradually adding features<a class="footnote-reference brackets" href="#notallmodels" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. We’ll describe the components of these models in more detail as we get to them, but briefly:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Gaussian</span></code>: the model just convolves a Gaussian with an image, so that the model’s representation is simply a blurry version of the image.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code>: the model convolves a difference-of-Gaussian filter with the image, so that model’s representation is bandpass, caring mainly about frequencies that are neither too high or too low.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LuminanceGainControl</span></code>: the model rectifies and normalizes the linear component of the response using a local measure of luminance, so that the response is invariant to local changes in luminance.</p></li>
</ul>
<section id="plenoptic-basics">
<h2>Plenoptic basics<a class="headerlink" href="#plenoptic-basics" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># enter code here</span>
</pre></div>
</div>
</div>
</div>
<p>— for Metamer synthesis, for example, this is the image whose representation we will match. Let’s load in an image of Einstein to serve as our reference here:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">einstein</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Models can be really simple, as this demonstrates. It needs to inherit <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code><a class="footnote-reference brackets" href="#module" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> and just needs two methods: <code class="docutils literal notranslate"><span class="pre">__init__</span></code> (so it’s an object) and <code class="docutils literal notranslate"><span class="pre">forward</span></code> (so it can take an image).</p>
<p>To start, we’ll create the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code> model described above:
Set up the Guassian model. Models in plenoptic must:</p>
<ul class="simple">
<li><p>Inherit <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>.</p></li>
<li><p>Accept tensors as input and return tensors as output.</p></li>
<li><p>Have <code class="docutils literal notranslate"><span class="pre">forward</span></code> and <code class="docutils literal notranslate"><span class="pre">__init__</span></code> methods.</p></li>
<li><p>Have all model parameter gradients removed.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># this is a convenience function for creating a simple Gaussian kernel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">plenoptic.simulate.canonical_computations.filters</span><span class="w"> </span><span class="kn">import</span> <span class="n">circular_gaussian2d</span>

<span class="c1"># Simple Gaussian convolutional model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Gaussian</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># in __init__, we create the object, initializing the convolutional weights and nonlinearity</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">std_dev</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">circular_gaussian2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">std_dev</span><span class="p">))</span>
        
    <span class="c1"># the forward pass of the model defines how to get from an image to the representation</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">same_padding</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;circular&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># we pick this particular number to match the models found in the Berardino paper</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Gaussian</span><span class="p">((</span><span class="mi">31</span><span class="p">,</span> <span class="mi">31</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">rep</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To work with our synthesis methods, a model must accept a tensor as input and return a tensor as output. Generally speaking, plenoptic works with 4d inputs: these are commonly used to represent images when working with pytorch models, and the dimensions are batch (often, multiple images), channel (often, RGB or outputs of different convolutional filters), height, and width. This is not required for a model to work with plenoptic’s synthesis methods, but several of the helper functions (especially those related to display) will not work if this is not the case.</p>
<p>We can see that our <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code> model satisfies this constraint:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rep</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>There’s one final step before this model is ready for synthesis. Most <code class="docutils literal notranslate"><span class="pre">pytorch</span></code> models will have learnable parameters, such as the weight on the convolution filter we created above, because the focus is generally on training the model to best perform some task. In <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code>, models are <em>fixed</em> because we take the opposite approach: generating some new stimulus to better a understand a given model. Thus, all synthesis methods will raise a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> if given a model with any learnable parameters. We provide a helper function to remove the gradients on these parameters. Similarly, we probably also want to call <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> on the model, in case it has training-mode specific behavior: that’s not the case here (I’m just being pedantic), but it might be the case, depending on your model, and <a class="reference external" href="https://pytorch.org/docs/stable/notes/autograd.html#evaluation-mode-nn-module-eval">pytorch’s documentation</a> recommends calling <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> just in case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The following shows the image and the model output. We can see that output is a blurred version of the input, as we would expect from a low-pass model.</p>
<ul class="simple">
<li><p>The Gaussian model output is a blurred version of the input.</p></li>
<li><p>This is because the model is preserving the low frequencies,  discarding the high frequencies (i.e., it’s a lowpass filter).</p></li>
<li><p>Thus, this model is completely insensitive to high frequencies – information there is invisible to the model.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">img</span><span class="p">,</span> <span class="n">rep</span><span class="p">]),</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Original image&#39;</span><span class="p">,</span> <span class="s1">&#39;Model output&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Before moving forward, let’s think about this model for a moment. It’s a simple Gaussian convolution which throws out high-frequency information, as we can see in the representation above. Metamers provide a tool for exploring a model’s insensitivities, so any metamers we synthesize should capitalize on this: they should differ from the original image in the high frequencies.</p>
</section>
<section id="examining-model-invariances-with-metamers">
<h2>Examining model invariances with metamers<a class="headerlink" href="#examining-model-invariances-with-metamers" title="Link to this heading">#</a></h2>
<p>Okay, now we’re ready to start with metamer synthesis. To initialize, we only need the model and the image. Optimization-related arguments are set when calling <code class="docutils literal notranslate"><span class="pre">.synthesize()</span></code> and, in general, you’ll probably need to play with these options to find a good solution. It’s also probably a good idea, while getting started, to set <code class="docutils literal notranslate"><span class="pre">store_progress</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> (to store every iteration) or some <code class="docutils literal notranslate"><span class="pre">int</span></code> (to store every <code class="docutils literal notranslate"><span class="pre">int</span></code> iterations) so you can examine synthesis progress.</p>
<ul class="simple">
<li><p>Initialize the <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object and synthesize a model metamer.</p></li>
<li><p>View the synthesis process.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>

<span class="n">matched_im</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1"># if we call synthesize again, we resume where we left off</span>
<span class="n">matched_im</span> <span class="o">=</span> <span class="n">metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">store_progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After synthesis runs, we can examine the loss over time. There’s a convenience function for this, but you could also call <code class="docutils literal notranslate"><span class="pre">plt.semilogy(metamer.losses)</span></code> to create it yourself.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">(</span><span class="n">metamer</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>The loss decreases steadily and has reached a very low value. In fact, based on our convergence criterion (one of the optional arguments), it looks as though we’ve converged (we could change this argument to continue synthesis).</p>
<p>We can also view a movie of our synthesis progress:</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>This next cell will take a while to run —</p>
</div>
<p>It may seem strange that the synthesized image looks like it has high-frequency noise in it — a Gaussian is a low-pass filter, so why isn’t the model metamer just a blurred version of the original image? Indeed, such a blurred image would be a model metamer, but it’s only one of many. Remember what we mentioned earlier: Gaussians are insensitive to high-frequency information, which not only means that their response doesn’t change when you remove that information, but that you can put any amount of high frequency information into an image without affecting the model’s output. Put another way, you can randomize the contents of the model’s null space without affecting its response, and the goal of metamer synthesis is to generate different images that do just that.</p>
<p>We can see the model’s insensitivity to high frequencies more dramatically by initializing our metamer synthesis with a different image. By default, we initialize with a patch of white noise, but we can initialize with any image of the same size. Let’s try with two different images, a sample of pink noise and a picture of Marie Curie.</p>
<ul class="simple">
<li><p>Synthesize more model metamers, from different starting points.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">curie</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">curie</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="c1"># pyrtools, imported as pt, has a convenience function for generating samples of white noise, but then we still </span>
<span class="c1"># need to do some annoying things to get it ready for plenoptic</span>
<span class="n">pink</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">synthetic_images</span><span class="o">.</span><span class="n">pink_noise</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pink</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pink</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">curie</span><span class="p">,</span> <span class="n">pink</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>We run synthesis in the same way as before, just setting the optional argument <code class="docutils literal notranslate"><span class="pre">initial_image</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">metamer_curie</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">metamer_curie</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">initial_image</span><span class="o">=</span><span class="n">curie</span><span class="p">)</span>
<span class="n">metamer_pink</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> 
<span class="n">metamer_pink</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">initial_image</span><span class="o">=</span><span class="n">pink</span><span class="p">)</span>

<span class="c1"># we increase the length of time we run synthesis and decrease the</span>
<span class="c1"># stop_criterion, which determines when we think loss has converged</span>
<span class="c1"># for stopping synthesis early.</span>
<span class="n">metamer_curie</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>  <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
<span class="n">metamer_pink</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>  <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s double-check that our synthesis looks like it’s reached a good solution by checking the loss curve:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">(</span><span class="n">metamer_curie</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">metamer</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">(</span><span class="n">metamer_pink</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>In the following plot:</p>
<ul class="simple">
<li><p>the first row shows our target Einstein image and its model representation, as we saw before.</p></li>
<li><p>the new three rows show our model metamers resulting from three different starting points.</p></li>
<li><p>in each, the first column shows the starting point of our metamer synthesis, the middle shows the resulting model metamer, and the third shows the model representation.</p></li>
</ul>
<p>We can see that the model representation is the same for all four images, but the images themselves look very different. Because the model is completely invariant to high frequencies, the high frequencies present in the initial image are not affected by the synthesis procedure and thus are still present in the model metamer.</p>
<p>Good, now let’s examine our synthesized metamer and the model output for all our initial images:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">img</span><span class="p">,</span> <span class="n">rep</span><span class="p">,</span>
                 <span class="n">metamer</span><span class="o">.</span><span class="n">saved_metamer</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">),</span>
                 <span class="n">pink</span><span class="p">,</span> <span class="n">metamer_pink</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer_pink</span><span class="o">.</span><span class="n">metamer</span><span class="p">),</span>
                 <span class="n">curie</span><span class="p">,</span> <span class="n">metamer_curie</span><span class="o">.</span><span class="n">metamer</span><span class="p">,</span> <span class="n">model</span><span class="p">(</span><span class="n">metamer_curie</span><span class="o">.</span><span class="n">metamer</span><span class="p">)],</span>
                <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Original image&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of original image&#39;</span><span class="p">]</span><span class="o">+</span>
                      <span class="mi">3</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Initial image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized metamer&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of synthesized metamer&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the new synthesized metamers looks quite different from both the original and from our previous metamer, while the model outputs of all the images look very similar. In the third row, the synthesized model metamer looks like a blurry picture of Einstein with a high-frequency “shadow” of Curie added on top. Again, this is because the Gaussian model is insensitive to high frequencies, and thus a model metamer can include any high frequency information. In the final row, we can see that our model metamer looks like a blurry picture of Einstein — because pink noise has very little information in the high frequencies (and the information that is present is incoherent), our resulting metamer appears to have little information present.</p>
</section>
<section id="examining-model-sensitivies-to-eigendistortions">
<h2>Examining model sensitivies to eigendistortions<a class="headerlink" href="#examining-model-sensitivies-to-eigendistortions" title="Link to this heading">#</a></h2>
<p>By generating model metamers, we’ve gained a better understanding of the information our model is invariant to, but what if we want a better understanding of what our model is sensitive to? We can use <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> for that.</p>
<p>Like <code class="docutils literal notranslate"><span class="pre">Metamer</span></code>, <code class="docutils literal notranslate"><span class="pre">Eigendistortion</span></code> accepts an image and a model as its inputs. By default, it synthesizes the top and bottom eigendistortion, that is, the changes to the input image that the model finds most and least noticeable.</p>
<ul class="simple">
<li><p>While metamers allow us to examine model invariances, eigendistortions allow us to also examine model sensitivities.</p></li>
<li><p>Eigendistortions are distortions that the model thinks are the most and least noticeable.</p></li>
<li><p>They can be visualized on their own or on top of the reference image.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">eig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">eig</span><span class="o">.</span><span class="n">synthesize</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s examine those distortions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">eig</span><span class="o">.</span><span class="n">eigendistortions</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Maximum eigendistortion&#39;</span><span class="p">,</span> 
                                       <span class="s1">&#39;Minimum eigendistortion&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>We can see they make sense: the most noticeable distortion is a very low-frequency modification to the image, with a period of about half the image. The least noticeable, on the other hand, is very high-frequency, which matches our understanding from the metamer example above. This is clearer if we add them to our Einstein in order to view them together:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">eig</span><span class="o">.</span><span class="n">eigendistortions</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Maximum eigendistortion&#39;</span><span class="p">,</span> 
                                               <span class="s1">&#39;Minimum eigendistortion&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-more-complex-model">
<h2>A more complex model<a class="headerlink" href="#a-more-complex-model" title="Link to this heading">#</a></h2>
<p>Now we feel pretty confident that we understand how a simple Gaussian works, what happens when we make the model more complicated? Let’s try changing the filter from a simple lowpass to a bandpass filter, which have sensitivities more similar to those of neurons in the early human visual system. To do this, we’ll use plenoptic’s built-in <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> object:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> model has bandpass sensitivity, as opposed to the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code>’s lowpass.</p></li>
<li><p>Thus, it is still insensitive to the highest frequencies, but it is less sensitive to the low frequencies the Gaussian prefers, with its peak sensitivity lying in a middling range.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># These values come from Berardino et al., 2017.</span>
<span class="n">center_surround</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simulate</span><span class="o">.</span><span class="n">CenterSurround</span><span class="p">((</span><span class="mi">31</span><span class="p">,</span> <span class="mi">31</span><span class="p">),</span> <span class="n">center_std</span><span class="o">=</span><span class="mf">1.962</span><span class="p">,</span> <span class="n">surround_std</span><span class="o">=</span><span class="mf">4.235</span><span class="p">,</span>
                                             <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;circular&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">center_surround</span><span class="p">)</span>
<span class="n">center_surround</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">center_surround</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<p>Before synthesizing our metamers, let’s look at the model representation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">img</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">(</span><span class="n">img</span><span class="p">)]);</span>
</pre></div>
</div>
</div>
</div>
<p>While the Gaussian model above was lowpass, throwing away high frequencies and preserving the low, the Center-Surround model is bandpass. It is thus most sensitive to frequencies found in the middle, and less sensitive to both high and low frequencies<a class="footnote-reference brackets" href="#bandpass" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>. We can see that in the figure above because the image looks “sharper” than the Gaussian representation (showing that it contains more high frequencies) while also being an overall “mean gray” (showing that it is discarding the low frequencies that account for making portions of the image dark or light).</p>
<p>We can make use of multi-batch processing in order to synthesize the metamers with different start points, as above, using a single <code class="docutils literal notranslate"><span class="pre">Metamer</span></code> object:</p>
<ul class="simple">
<li><p>We can synthesize all three model metamers at once by taking advantage of multi-batch processing.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">white_noise</span> <span class="o">=</span>  <span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">init_img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">white_noise</span><span class="p">,</span> <span class="n">pink</span><span class="p">,</span> <span class="n">curie</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># metamer does a 1-to-1 matching between initial and target images,</span>
<span class="c1"># so we need to repeat the target image on the batch dimension</span>
<span class="n">cs_metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">center_surround</span><span class="p">)</span>
<span class="n">cs_metamer</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">initial_image</span><span class="o">=</span><span class="n">init_img</span><span class="p">)</span>
<span class="n">cs_metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s visualize our outputs (the code to create this plot is slightly annoying, so we’re hiding it):</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># this requires a little reorganization of the tensors:</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">img</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">(</span><span class="n">img</span><span class="p">)])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">init_img</span><span class="p">,</span> <span class="n">cs_metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">):</span>
    <span class="n">to_plot</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">(</span><span class="n">j</span><span class="p">)]))</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">to_plot</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">to_plot</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Original image&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of original image&#39;</span><span class="p">]</span><span class="o">+</span>
                       <span class="mi">3</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Initial image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized metamer&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of synthesized metamer&#39;</span><span class="p">]);</span>
<span class="c1"># change the color scale of the images so that the first two columns go from 0 to 1 </span>
<span class="c1"># and the last one is consistent</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;representation&#39;</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">():</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="p">(</span><span class="n">to_plot</span><span class="p">[</span><span class="mi">2</span><span class="p">::</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">to_plot</span><span class="p">[</span><span class="mi">2</span><span class="p">::</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_clim</span><span class="p">(</span><span class="o">*</span><span class="n">clim</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">title</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; range: [</span><span class="si">{</span><span class="n">clim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.01e</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">clim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.01e</span><span class="si">}</span><span class="s2">]&quot;</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>The layout of the plots here is the same as before: the top row shows our target image and its model representation, while the next rows each show a separate model metamer in the middle column, with their different initial points in the left column and their model representations on the right. We can see that the model representation in each row looks the same, while the middle columns look very different.</p>
<div class="docutils">
</div>
<p>While these model metamers look reasonably similar to the metamers of the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code> model, a somewhat blurry Einstein with some additional info riding on top, if we look carefully, we can notice some important differences:</p>
<ul class="simple">
<li><p>in the white noise metamer, the mean values appear to be different: the dark side of the room on the left side of the picture, as well as his suit, appear to be lighter.</p></li>
<li><p>whereas the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code> pink noise metamer just appeared to be blurry, the <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> one has dark and light patches that roughly match up with the original noise seed.</p></li>
<li><p>the differences are most striking in the Curie metamer, as the initial image was completely black except for Marie Curie’s face, which is fairly white. The resulting metamer, therefore, is much darker than the target everywhere except the center of the image, which is much brighter.</p></li>
</ul>
<p>In all of these, the differences are the result of the fact that our model now consists of a <a class="reference external" href="https://en.wikipedia.org/wiki/Difference_of_Gaussians">difference-of-Gaussians filter</a> than a Gaussian. As described earlier, this results in a model with <em>bandpass</em> selectivity, rather than <em>lowpass</em>. Thus, the <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> doesn’t care about low frequency information like the local mean pixel value and we can change it without affecting its output<a class="footnote-reference brackets" href="#bandpass" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>.</p>
<p>The change from a lowpass to a bandpass model also changes the model’s most sensitive frequencies, though we can’t easily tell that using model metamers. We can, however, using eigendistortions!</p>
<ul class="simple">
<li><p>By examining the eigendistortions, we can see more clearly that the model’s preferred frequency has shifted higher, while the minimal eigendistortion still looks fairly similar.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cs_eig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">)</span>
<span class="n">cs_eig</span><span class="o">.</span><span class="n">synthesize</span><span class="p">();</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cs_eig</span><span class="o">.</span><span class="n">eigendistortions</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Maximum eigendistortion&#39;</span><span class="p">,</span> 
                                          <span class="s1">&#39;Minimum eigendistortion&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>In this case, we can see that the minimum eigendistortion looks similar to that of the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code>: an unoriented pattern of high-frequency noise. The maximum eigendistortion, however, has a much higher frequency than that of the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code>, corresponding to the change in the filter.</p>
</section>
<section id="adding-some-nonlinear-features-to-the-mix">
<h2>Adding some nonlinear features to the mix<a class="headerlink" href="#adding-some-nonlinear-features-to-the-mix" title="Link to this heading">#</a></h2>
<p>So far, our models have all been linear. That means that they’re easy to understand, and we could indeed infer much of the information above by just looking at the Fourier transform of the model’s filter<a class="footnote-reference brackets" href="#fft" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a>. However, if we add nonlinear features, analysis of model selectivity becomes trickier. To see what this looks like, let’s use the <code class="docutils literal notranslate"><span class="pre">LuminanceGainControl</span></code> model, which adds gain control<a class="footnote-reference brackets" href="#gaincontrol" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a>: we take the output of the filter and divide it by the local luminance.</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">LuminanceGainControl</span></code> model adds a nonlinearity, gain control. This makes the model harder to reason than the first two models.</p></li>
<li><p>This model divides the output of the <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> filter with an estimate of local luminance (the output of a larger Gaussian filter), which makes the model completely insensitive to absolute pixel values. It now cares about contrast, rather than luminance.</p></li>
<li><p>This is a computation that we think is present throughout much of the early visual system.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lg</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">simulate</span><span class="o">.</span><span class="n">LuminanceGainControl</span><span class="p">((</span><span class="mi">31</span><span class="p">,</span> <span class="mi">31</span><span class="p">),</span> <span class="n">pad_mode</span><span class="o">=</span><span class="s2">&quot;circular&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">params_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;luminance_scalar&#39;</span><span class="p">:</span> <span class="mf">14.95</span><span class="p">,</span> <span class="s1">&#39;luminance.std&#39;</span><span class="p">:</span> <span class="mf">4.235</span><span class="p">,</span> 
               <span class="s1">&#39;center_surround.center_std&#39;</span><span class="p">:</span> <span class="mf">1.962</span><span class="p">,</span> <span class="s1">&#39;center_surround.surround_std&#39;</span><span class="p">:</span> <span class="mf">4.235</span><span class="p">,</span>
               <span class="s1">&#39;center_surround.amplitude_ratio&#39;</span><span class="p">:</span> <span class="mf">1.25</span><span class="p">}</span>
<span class="n">lg</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="n">v</span><span class="p">])</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
<span class="n">po</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">remove_grad</span><span class="p">(</span><span class="n">lg</span><span class="p">)</span>
<span class="n">lg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This builds in additional invariances to the model, making it explicitly less sensitive to changes in the local luminance, so that if you double all the pixel values in the image, the model’s response remains the same:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">([</span><span class="n">lg</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">lg</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">img</span><span class="p">)],</span> <span class="n">vrange</span><span class="o">=</span><span class="s1">&#39;auto1&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s go ahead and synthesize and visualize metamers for this model. This will look the same as before, except we’re going to explicitly initialize the optimizer object. This allows us to set the learning rate to a value slightly lower than the default, which allows us to find a better solution here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lg_metamer</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Metamer</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">lg</span><span class="p">)</span>
<span class="n">lg_metamer</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">initial_image</span><span class="o">=</span><span class="n">init_img</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">.007</span><span class="p">})</span>
<span class="n">lg_metamer</span><span class="o">.</span><span class="n">synthesize</span><span class="p">(</span><span class="mi">3500</span><span class="p">,</span> <span class="n">stop_criterion</span><span class="o">=</span><span class="mf">1e-11</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And let’s visualize our results:</p>
<ul class="simple">
<li><p>The model metamers here look fairly similar to those of the <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> model, though you can see these are more “gray”, because this model is even less sensitive to the local luminance than the previous model.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># this requires a little reorganization of the tensors:</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">img</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">(</span><span class="n">img</span><span class="p">)])]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">init_img</span><span class="p">,</span> <span class="n">lg_metamer</span><span class="o">.</span><span class="n">metamer</span><span class="p">):</span>
    <span class="n">to_plot</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">center_surround</span><span class="p">(</span><span class="n">j</span><span class="p">)]))</span>
<span class="n">to_plot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">to_plot</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">to_plot</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="s1">&#39;Original image&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of original image&#39;</span><span class="p">]</span><span class="o">+</span>
                       <span class="mi">3</span><span class="o">*</span><span class="p">[</span><span class="s1">&#39;Initial image&#39;</span><span class="p">,</span> <span class="s1">&#39;Synthesized metamer&#39;</span><span class="p">,</span> <span class="s1">&#39;Model representation</span><span class="se">\n</span><span class="s1">of synthesized metamer&#39;</span><span class="p">]);</span>
<span class="c1"># change the color scale of the images so that the first two columns go from 0 to 1 </span>
<span class="c1"># and the last one is consistent</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;representation&#39;</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">():</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="p">(</span><span class="n">to_plot</span><span class="p">[</span><span class="mi">2</span><span class="p">::</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">to_plot</span><span class="p">[</span><span class="mi">2</span><span class="p">::</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">clim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_clim</span><span class="p">(</span><span class="o">*</span><span class="n">clim</span><span class="p">)</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_title</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">title</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; range: [</span><span class="si">{</span><span class="n">clim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.01e</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">clim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.01e</span><span class="si">}</span><span class="s2">]&quot;</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">title</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>We can see that the <code class="docutils literal notranslate"><span class="pre">LuminanceGainControl</span></code> model metamers look somewhat similar to that of the <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> model, but taking the insensitivity to pixel values to an extreme — because of the division by the local luminance, the model is completely invariant to it, so that the mean pixel values match those of the initializing image, fairly drmaatically.</p>
<p>Finally, let’s look at our eigendistortions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lg_eig</span> <span class="o">=</span> <span class="n">po</span><span class="o">.</span><span class="n">synthesize</span><span class="o">.</span><span class="n">Eigendistortion</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lg</span><span class="p">)</span>
<span class="n">lg_eig</span><span class="o">.</span><span class="n">synthesize</span><span class="p">();</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">lg_eig</span><span class="o">.</span><span class="n">eigendistortions</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Maximum eigendistortion&#39;</span><span class="p">,</span> 
                                          <span class="s1">&#39;Minimum eigendistortion&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<div class="docutils">
<ul class="simple">
<li><p>Gain control makes this model adaptive, and thus the location of the eigendistortion matters, which was not true of our previous, linear models.</p></li>
</ul>
<p class="rubric" id="conclusion">Conclusion</p>
<p>In this notebook, we saw the basics of using <code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> to investigate the sensitivities and invariances of some simple convolutional models, and reasoned through how the model metamers and eigendistortions we saw enable us to understand how these models process images.</p>
<p><code class="docutils literal notranslate"><span class="pre">plenoptic</span></code> includes a variety of models and model components in the <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/api/plenoptic.simulate.html">plenoptic.simulate</a> module, and you can (and should!) use the synthesis methods with your own models. Our documentation also has <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/tutorials/applications/Demo_Eigendistortion.html">examples</a> showing how to use models from <a class="reference external" href="https://pytorch.org/vision/stable/index.html">torchvision</a> (which contains a variety of pretrained neural network models) with plenoptic (we’ll be releasing a simpler interface for torchvision and other pytorch model zoos this summer – ask me if you’re interested!). In order to use your own models with plenoptic, check the <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/models.html">documentation</a> for the specific requirements, and use the <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/api/plenoptic.tools.html#plenoptic.tools.validate.validate_model"><code class="docutils literal notranslate"><span class="pre">validate_model</span></code></a> function to check compatibility. If you have issues or want feedback, we’re happy to help — just post on the <a class="reference external" href="https://github.com/plenoptic-org/plenoptic/discussions">Github discussions page</a>!</p>
</div>
</section>
</section>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="models" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Most of these models were originally published in Berardino, A., Laparra, V., J Ball’e, &amp; Simoncelli, E. P. (2017). Eigen-distortions of hierarchical representations. In Adv. Neural Information Processing Systems (NIPS*17), from which the figure is modified.</p>
</aside>
<aside class="footnote brackets" id="notallmodels" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Note that the Berardino et. al, 2017 paper includes more models than described here. We’re not examining all of them for time’s sake, but you can check out the rest of the models described in the Berardino paper, they’re all included in plenoptic under the <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/api/plenoptic.simulate.models.html#module-plenoptic.simulate.models.frontend">plenoptic.simulate.FrontEnd</a> module!</p>
</aside>
<aside class="footnote brackets" id="module" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Technically, this isn’t necessary, but it will make your life easier. See <a class="reference external" href="https://docs.plenoptic.org/docs/branch/main/models.html">our documentation</a> for details.</p>
</aside>
<aside class="footnote brackets" id="bandpass" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span>
<p>The <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> model does retain some sensitivity to lower frequencies, but it’s much less sensitive to them than the <code class="docutils literal notranslate"><span class="pre">Gaussian</span></code> model is. The <code class="docutils literal notranslate"><span class="pre">CenterSurround</span></code> retains some low frequency selectivity because its two Gaussians are not perfectly balanced; to play around with their balance, try changing the <code class="docutils literal notranslate"><span class="pre">amplitude_ratio</span></code> argument.</p>
</aside>
<aside class="footnote brackets" id="fft" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id6">5</a><span class="fn-bracket">]</span></span>
<p>Try it yourself!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cs_filt</span> <span class="o">=</span> <span class="n">center_surround</span><span class="o">.</span><span class="n">filt</span>
<span class="n">gauss_filt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
<span class="n">filts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">cs_filt</span><span class="p">,</span> <span class="n">gauss_filt</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">energy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftshift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">(</span><span class="n">filts</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span>
<span class="n">po</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">energy</span><span class="p">)</span>
</pre></div>
</div>
</aside>
<aside class="footnote brackets" id="gaincontrol" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id7">6</a><span class="fn-bracket">]</span></span>
<p>Gain control, or divisive normalization, is ubiquitous in the central nervous system and has been proposed as a <a class="reference external" href="https://www.nature.com/articles/nrn3136">canonical neural computation</a> which allows the brain to maximize sensitivity to relevant stimuli in changing contexts.</p>
</aside>
</aside>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../full/introduction.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction</p>
      </div>
    </a>
    <a class="right-next"
       href="../presenters/introduction-presenters.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plenoptic-basics">Plenoptic basics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-model-invariances-with-metamers">Examining model invariances with metamers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examining-model-sensitivies-to-eigendistortions">Examining model sensitivies to eigendistortions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-more-complex-model">A more complex model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-some-nonlinear-features-to-the-mix">Adding some nonlinear features to the mix</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Billy Broderick
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, Billy Broderick.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>